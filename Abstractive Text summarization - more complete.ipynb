{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4ae4572",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b72f9635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 10:35:38.743910: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/oem/catkin_ws/devel/lib:/opt/ros/noetic/lib\n",
      "2022-05-11 10:35:38.743975: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf107425",
   "metadata": {},
   "source": [
    "# Read the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccd27495",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"archive/Reviews.csv\",nrows=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f775be",
   "metadata": {},
   "source": [
    "# Drop Duplicates and NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "323ba69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=['Text'],inplace=True)#dropping duplicates\n",
    "data.dropna(axis=0,inplace=True)#dropping na"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783b6e25",
   "metadata": {},
   "source": [
    "# Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b736b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def text_cleaner(text,num):\n",
    "    newString = text.lower()\n",
    "    newString = BeautifulSoup(newString, \"lxml\").text\n",
    "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
    "    newString = re.sub('\"','', newString)\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
    "    if(num==0):\n",
    "        tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    else:\n",
    "        tokens=newString.split()\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                                 #removing short word\n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()\n",
    "\n",
    "#call the function (Text)\n",
    "cleaned_text = []\n",
    "for t in data['Text']:\n",
    "    cleaned_text.append(text_cleaner(t,0)) \n",
    "    \n",
    "#call the function (Summary)\n",
    "cleaned_summary = []\n",
    "for t in data['Summary']:\n",
    "    cleaned_summary.append(text_cleaner(t,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43c71953",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned_text']=cleaned_text\n",
    "data['cleaned_summary']=cleaned_summary\n",
    "# Drop empty rows\n",
    "data.replace('', np.nan, inplace=True)\n",
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acc432ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_len=100\n",
    "max_summary_len=8\n",
    "\n",
    "cleaned_text =np.array(data['cleaned_text'])\n",
    "cleaned_summary=np.array(data['cleaned_summary'])\n",
    "\n",
    "short_text=[]\n",
    "short_summary=[]\n",
    "\n",
    "for i in range(len(cleaned_text)):\n",
    "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
    "        short_text.append(cleaned_text[i])\n",
    "        short_summary.append(cleaned_summary[i])\n",
    "        \n",
    "df=pd.DataFrame({'text':short_text,'summary':short_summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3674bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "716fefd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=0,shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "948967a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81238eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 65.38833609729132\n",
      "Total Coverage of rare words: 5.5937115241262045\n"
     ]
    }
   ],
   "source": [
    "thresh=4\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a56696bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "x_voc   =  x_tokenizer.num_words + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65700023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d933570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 82.72308109574179\n",
      "Total Coverage of rare words: 11.944548170276326\n"
     ]
    }
   ],
   "source": [
    "thresh=6\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in y_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afd837fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
    "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "#size of vocabulary\n",
    "y_voc  =   y_tokenizer.num_words +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f99624c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_tr)):\n",
    "    cnt=0\n",
    "    for j in y_tr[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_tr=np.delete(y_tr,ind, axis=0)\n",
    "x_tr=np.delete(x_tr,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d77cf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_val)):\n",
    "    cnt=0\n",
    "    for j in y_val[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_val=np.delete(y_val,ind, axis=0)\n",
    "x_val=np.delete(x_val,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4c7182a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 100, 100)     501000      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 100, 300),   481200      ['embedding[0][0]']              \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 100, 300),   721200      ['lstm[0][0]']                   \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 100)    63800       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 100, 300),   721200      ['lstm_1[0][0]']                 \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 300),  481200      ['embedding_1[0][0]',            \n",
      "                                 (None, 300),                     'lstm_2[0][1]',                 \n",
      "                                 (None, 300)]                     'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " additive_attention (AdditiveAt  (None, None, 300)   300         ['lstm_3[0][0]',                 \n",
      " tention)                                                         'lstm_2[0][0]']                 \n",
      "                                                                                                  \n",
      " concat_layer (Concatenate)     (None, None, 600)    0           ['lstm_3[0][0]',                 \n",
      "                                                                  'additive_attention[0][0]']     \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, None, 638)   383438      ['concat_layer[0][0]']           \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,353,338\n",
      "Trainable params: 3,353,338\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K \n",
    "from tensorflow.keras.layers import AdditiveAttention\n",
    "K.clear_session()\n",
    "\n",
    "latent_dim = 300\n",
    "embedding_dim=100\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "\n",
    "#embedding layer\n",
    "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "#encoder lstm 1\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "#encoder lstm 2\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#encoder lstm 3\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "#embedding layer\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "# Attention layer\n",
    "attn_out = AdditiveAttention(use_scale=True)([decoder_outputs, encoder_outputs])\n",
    "\n",
    "# Concat attention input and decoder LSTM output\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "#dense layer\n",
    "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "# Define the model \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "693e561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "# model.compile(optimizer = 'adam', loss = 'mean_square_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ec02acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11/58 [====>.........................] - ETA: 1:47 - loss: 1.9709"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7924/309444028.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)\n",
    "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=20,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7123be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c31aeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_word_index=y_tokenizer.index_word\n",
    "reverse_source_word_index=x_tokenizer.index_word\n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05b5b2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the feature vector\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) \n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "attn_out_inf = AdditiveAttention(use_scale=True)([decoder_outputs2, decoder_hidden_state_input])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "440ceab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = target_word_index['sostok']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "      \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        \n",
    "        if(sampled_token!='eostok'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ea3d0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
    "            newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef50d04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: love light airy crackers three calories ww spread reduced fat peanut butter light part light lunch used buy supermarket always found amazon thrilled using automatic reorder feature saved cost shipping might add change frequency time \n",
      "Original summary: crackers great low calorie option \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: fresh scent taste easy eat one tin hours use favors everyone loved \n",
      "Original summary: fresh \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: sure guy like much love fact might one favorite foods around tried true rarely cooks wrong always good warm belly flavor good tried brands bit makes best ramen noodles time \n",
      "Original summary: the best around \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: really want like product great things newman done fact go charity like fact ingredients top quality organic looks smells good unfortunately none matters dog care usually sniff walk away nothing else coming way usually eat feel bad since obviously care like said really want like product dog final say sadly think buy \n",
      "Original summary: my dog is not impressed \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: bbq chips great liked better regular chips nice crunch hate kettle chips hard like eating glass definitely buying popchips \n",
      "Original summary: love these chips \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: hi black tea everyday done past years habit mine ahmad tea one favorite brands highly recommend like black tea think going remain favorite next years \n",
      "Original summary: my cup of tea \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: tried many brands sardines favorite even low sodium full flavor excellent choice \n",
      "Original summary: good choice \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: used buyer natural organic grocery best soup ever picky clam chowder soup favorite clam chowder add butter milk cream black pepper fresh corn bread butter heaven \n",
      "Original summary: the best \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: love substitute brown sugar always stays moist one tell using instead regular brown sugar \n",
      "Original summary: tastes like real brown sugar \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: closely resembles cracker except soy disappointed taste texture quality cracker enjoy \n",
      "Original summary: tasty no soy cracker \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: tried normal red tea waited review flavor still head rooibos tea less color muddy water well well worth every penny \n",
      "Original summary: tasted better than loose leaf \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: chia seeds fresh shiny clean easy use add various recipes hardly see taste know make healthier \n",
      "Original summary: fresh and clean \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: would surprised much runa tea help daily life thirsty hot cold tea help many ways college student cannot take prescribed time keep attention instead turn caffeine day every day runa tea one products really caused feel refreshed hydrated run well feeling ready write page paper scratch know makes feel good every way personally love cold tea consumer everyone needs find huge hot tea drinker chose cold version either way thing need try try star opinions \n",
      "Original summary: do not it try it \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: like dried peas tomatoes also like corn way expensive though really handy use frozen canned foods follow diet find fresh peas use probably without cannot afford bad \n",
      "Original summary: very good but too expensive \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: bigger always better said got turned coconut water year ago since able get enough found vita coco best brand around pineapple flavor great sweetness compliments coconut water create refreshing thirst quenching beverage recently began drink due nature job hands plus nutrients benefits whats like subscribe save quench thirst time year thanks vita coco surely lovely bunch \n",
      "Original summary: same great taste just more of it \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: coffee quality good expected close next time spend extra dollars buy coffee \n",
      "Original summary: close to date \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: find tea bitter taste difficult cost teas cheap anymore trying many healing teas stevia added could get past taste tea bitter nice smooth flavor hot cold feel energized drinking jittery feeling awake alert feeling refreshed energized physical feeling reviewers state sweet taste get often add packet sugar raw perhaps mean add sugar replaced second cup coffee morning tea even another cup throughout day instead coffee excellent taste around great product \n",
      "Original summary: no great flavor and it does work \n",
      "Predicted summary:  great coffee\n",
      "\n",
      "\n",
      "Review: taste good opinion found overly salty buy cheaper alternative want know source ingredients ask company soy natural ingredient sure star review \n",
      "Original summary: good crackers \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: classic pasta requires beautiful mild form bacon every product purchased la guanciale little guanciale bit still tender diced tomatoes little pinch crushed red pepper done guanciale star guanciale really stands served pasta might well \n",
      "Original summary: perfect for so many things \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: lollipops pictured came assorted colors really shown picture also completely flat rather rolled old fashioned candy style look cheap need birthday party really disappointed received \n",
      "Original summary: not as \n",
      "Predicted summary:  great\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,20):\n",
    "    print(\"Review:\",seq2text(x_tr[i]))\n",
    "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
    "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5068f3ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
